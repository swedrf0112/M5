{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5_seq2seq_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p182RV1A6MuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/m5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33RuQmw282kI",
        "colab_type": "code",
        "outputId": "a42b805d-f8e4-4199-c935-61c2b46d8276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import functools\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2FS2xyw6uyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAaZk04zslX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-cN7e26Mnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SERIES_SIZE = 60\n",
        "OUTPUT_SERIES_SIZE = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgv73g_RnDow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "UNITS = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epF0mG8W89Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales_df = pd.read_csv(\"/m5/My Drive/m5-forecasting-accuracy/sales_train_validation.csv\")\n",
        "calendar_df = pd.read_csv(\"/m5/My Drive/m5-forecasting-accuracy/calendar.csv\")\n",
        "prices_df = pd.read_csv(\"/m5/My Drive/m5-forecasting-accuracy/sell_prices.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDtI-hkdsRDD",
        "colab_type": "code",
        "outputId": "e56f633f-0a53-4cdf-818d-40ab818e83a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "pd.read_csv(\"/m5/My Drive/m5-forecasting-accuracy/sell_prices.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11325</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11326</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11327</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11328</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11329</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6841116</th>\n",
              "      <td>WI_3</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>11617</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6841117</th>\n",
              "      <td>WI_3</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>11618</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6841118</th>\n",
              "      <td>WI_3</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>11619</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6841119</th>\n",
              "      <td>WI_3</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>11620</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6841120</th>\n",
              "      <td>WI_3</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>11621</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6841121 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        store_id        item_id  wm_yr_wk  sell_price\n",
              "0           CA_1  HOBBIES_1_001     11325        9.58\n",
              "1           CA_1  HOBBIES_1_001     11326        9.58\n",
              "2           CA_1  HOBBIES_1_001     11327        8.26\n",
              "3           CA_1  HOBBIES_1_001     11328        8.26\n",
              "4           CA_1  HOBBIES_1_001     11329        8.26\n",
              "...          ...            ...       ...         ...\n",
              "6841116     WI_3    FOODS_3_827     11617        1.00\n",
              "6841117     WI_3    FOODS_3_827     11618        1.00\n",
              "6841118     WI_3    FOODS_3_827     11619        1.00\n",
              "6841119     WI_3    FOODS_3_827     11620        1.00\n",
              "6841120     WI_3    FOODS_3_827     11621        1.00\n",
              "\n",
              "[6841121 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mQrNR7Q7RVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv(\"/m5/My Drive/m5-forecasting-accuracy/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsK-FQjy1ViH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sales_df = sales_df[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] + [\"d_{0}\".format(i) for i in range(1826, 1914, 1)]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFxYtQ_71uHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # 2016-04-25 ~ 2016-05-22 是需要prediction的 time\n",
        "#calendar_df[(calendar_df['int_d'] > 1913) & (calendar_df['int_d'] <= 1913 + 28)]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RfkBy0utMzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_df = sales_df.iloc[[23, 1042, 7984]].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWqZZzyXl1_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BuildSalesDF:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "    self.label_encoder_dict = {}\n",
        "    self.min_max_scaler = MinMaxScaler()\n",
        "    self.tot_data_list = []\n",
        "    self.data_x = []\n",
        "    self.data_y = []\n",
        "    self.series_length = self.df.shape[1] - 6\n",
        "\n",
        "  def buildLabelEncoder(self, target_column):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(self.df[target_column])\n",
        "    self.label_encoder_dict[target_column] = le\n",
        "    self.df[target_column + '_index'] = le.transform(self.df[target_column])\n",
        "    self.df = self.df.drop(target_column, axis = 1)\n",
        "\n",
        "  def build(self):\n",
        "    for col in ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']:\n",
        "      self.buildLabelEncoder(col)\n",
        "\n",
        "    self.df = self.df.melt(id_vars = ['id', 'item_id_index', 'dept_id_index', 'cat_id_index', 'store_id_index', 'state_id_index'])\n",
        "    self.min_max_scaler.fit(self.df['value'].values.reshape(-1, 1))\n",
        "    self.df['value'] = self.min_max_scaler.transform(self.df['value'].values.reshape(-1, 1))\n",
        "\n",
        "    self.df = self.df.rename(columns = {'variable': 'd'})\n",
        "    self.df['d'] = list(map(lambda x: int(x.replace('d_', '')), self.df['d']))\n",
        "\n",
        "    groupDF = self.df.groupby('id')\n",
        "    for x in groupDF.groups:\n",
        "      self.tot_data_list.append(groupDF.get_group(x).sort_values('d'))\n",
        "\n",
        "  def transformAllData(self):\n",
        "      last_t = self.series_length - INPUT_SERIES_SIZE - OUTPUT_SERIES_SIZE + 1\n",
        "\n",
        "      for idx in tqdm(range(len(self.tot_data_list))):\n",
        "        for t in range(last_t):\n",
        "          dd = self.tot_data_list[idx][['item_id_index', 'dept_id_index', 'cat_id_index', 'store_id_index', 'state_id_index', 'value']].to_numpy()\n",
        "          self.data_x.append(dd[t:(t + INPUT_SERIES_SIZE), :])\n",
        "          self.data_y.append(dd[(t + INPUT_SERIES_SIZE):(t + INPUT_SERIES_SIZE + OUTPUT_SERIES_SIZE), -1].reshape(OUTPUT_SERIES_SIZE, 1))\n",
        "\n",
        "  def run(self):\n",
        "    self.build()\n",
        "    print(\"Transform data into list...\")\n",
        "    self.transformAllData()\n",
        "    self.all_data_x = np.array(self.data_x, dtype = np.float32)\n",
        "    self.all_data_y = np.array(self.data_y, dtype = np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-kM1PdFnz8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales_df_obj = BuildSalesDF(test_sales_df)\n",
        "sales_df_obj.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MFngTGfnboD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(sales_df_obj.all_data_x, sales_df_obj.all_data_y, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKsmAXQylLnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = train_x.shape[0] // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPIxCeUzlLiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cJeJQ0XmD33-",
        "colab": {}
      },
      "source": [
        "# example_input_batch, example_target_batch = next(iter(train_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JBAU8YVrLo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_id_embedding_layer = Embedding(3049, 10, input_length = BATCH_SIZE)\n",
        "dept_id_embedding_layer = Embedding(7, 2, input_length = BATCH_SIZE)\n",
        "cat_id_embedding_layer = Embedding(3, 1, input_length = BATCH_SIZE)\n",
        "store_id_embedding_layer = Embedding(10, 2, input_length = BATCH_SIZE)\n",
        "state_id_embedding_layer = Embedding(3, 1, input_length = BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG0xffRZumz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# item_e = item_id_embedding_layer(example_input_batch[:,:,0])\n",
        "# dept_e = dept_id_embedding_layer(example_input_batch[:,:,1])\n",
        "# cat_e = cat_id_embedding_layer(example_input_batch[:,:,2])\n",
        "# store_e = store_id_embedding_layer(example_input_batch[:,:,3])\n",
        "# state_e = state_id_embedding_layer(example_input_batch[:,:,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1PKES3frLlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtt_KxEirLgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2EJu4heqAw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, \n",
        "                                   return_sequences = True, \n",
        "                                   return_state = True, \n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46QgnoUbqAs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDccQK1dqAp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, \n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True, \n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "    #self.fc = tf.keras.layers.Dense(self.dec_units)\n",
        "    self.fc = tf.keras.layers.Dense(1, activation = 'relu')\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    #x = tf.expand_dims(x, 1)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "    \n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Man21lKpqAnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(UNITS, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfRN979SqAkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(UNITS, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZozYAuJqAg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_function = tf.keras.losses.MeanSquaredError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mix-G6LFtXuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxwvFNgqcbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    item_e = item_id_embedding_layer(inp[:,:,0])\n",
        "    dept_e = dept_id_embedding_layer(inp[:,:,1])\n",
        "    cat_e = cat_id_embedding_layer(inp[:,:,2])\n",
        "    store_e = store_id_embedding_layer(inp[:,:,3])\n",
        "    state_e = state_id_embedding_layer(inp[:,:,4])\n",
        "\n",
        "    inp_embedding = tf.concat([item_e, dept_e, cat_e, store_e, state_e, tf.expand_dims(inp[:,:,5], 2)], axis = 2)\n",
        "\n",
        "    enc_output, enc_hidden = encoder(inp_embedding, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    \n",
        "    dec_input = tf.expand_dims(tf.expand_dims([-1.0] * BATCH_SIZE, 1), 1)\n",
        "    #print(\"init: \", dec_input.shape)\n",
        "\n",
        "    for t in range(targ.shape[1]):\n",
        "    #  print(t)\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      #print(\"targ[:, t]: \", targ[:, t].shape, \"prev: \", dec_input.shape)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "     # print(\"after: \", dec_input.shape)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU2WX6v4qcX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNaQriTPqcVb",
        "colab_type": "code",
        "outputId": "8830d65a-9fc5-4a45-937d-67a962dd52bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.10f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "\n",
        "  print('Epoch {} Loss {:.10f}'.format(epoch + 1, total_loss/STEPS_PER_EPOCH))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1 Batch 0 Loss 0.0001057962\n",
            "Epoch 1 Loss 0.0001096272\n",
            "Epoch 2 Batch 0 Loss 0.0000655849\n",
            "Epoch 2 Loss 0.0000790138\n",
            "Epoch 3 Batch 0 Loss 0.0000620850\n",
            "Epoch 3 Loss 0.0000782464\n",
            "Epoch 4 Batch 0 Loss 0.0000629718\n",
            "Epoch 4 Loss 0.0000775970\n",
            "Epoch 5 Batch 0 Loss 0.0000624393\n",
            "Epoch 5 Loss 0.0000771976\n",
            "Epoch 6 Batch 0 Loss 0.0000626015\n",
            "Epoch 6 Loss 0.0000772470\n",
            "Epoch 7 Batch 0 Loss 0.0000622713\n",
            "Epoch 7 Loss 0.0000773168\n",
            "Epoch 8 Batch 0 Loss 0.0000614988\n",
            "Epoch 8 Loss 0.0000777285\n",
            "Epoch 9 Batch 0 Loss 0.0000623216\n",
            "Epoch 9 Loss 0.0000769354\n",
            "Epoch 10 Batch 0 Loss 0.0000624742\n",
            "Epoch 10 Loss 0.0000765916\n",
            "Epoch 11 Batch 0 Loss 0.0000621709\n",
            "Epoch 11 Loss 0.0000761879\n",
            "Epoch 12 Batch 0 Loss 0.0000619059\n",
            "Epoch 12 Loss 0.0000763825\n",
            "Epoch 13 Batch 0 Loss 0.0000620088\n",
            "Epoch 13 Loss 0.0000762038\n",
            "Epoch 14 Batch 0 Loss 0.0000619517\n",
            "Epoch 14 Loss 0.0000764178\n",
            "Epoch 15 Batch 0 Loss 0.0000616929\n",
            "Epoch 15 Loss 0.0000763174\n",
            "Epoch 16 Batch 0 Loss 0.0000616587\n",
            "Epoch 16 Loss 0.0000764482\n",
            "Epoch 17 Batch 0 Loss 0.0000616311\n",
            "Epoch 17 Loss 0.0000763177\n",
            "Epoch 18 Batch 0 Loss 0.0000616211\n",
            "Epoch 18 Loss 0.0000763449\n",
            "Epoch 19 Batch 0 Loss 0.0000616377\n",
            "Epoch 19 Loss 0.0000762550\n",
            "Epoch 20 Batch 0 Loss 0.0000616387\n",
            "Epoch 20 Loss 0.0000762650\n",
            "Epoch 21 Batch 0 Loss 0.0000616877\n",
            "Epoch 21 Loss 0.0000761795\n",
            "Epoch 22 Batch 0 Loss 0.0000616968\n",
            "Epoch 22 Loss 0.0000762280\n",
            "Epoch 23 Batch 0 Loss 0.0000617377\n",
            "Epoch 23 Loss 0.0000761608\n",
            "Epoch 24 Batch 0 Loss 0.0000617435\n",
            "Epoch 24 Loss 0.0000761940\n",
            "Epoch 25 Batch 0 Loss 0.0000617841\n",
            "Epoch 25 Loss 0.0000761512\n",
            "Epoch 26 Batch 0 Loss 0.0000617914\n",
            "Epoch 26 Loss 0.0000761925\n",
            "Epoch 27 Batch 0 Loss 0.0000618386\n",
            "Epoch 27 Loss 0.0000761544\n",
            "Epoch 28 Batch 0 Loss 0.0000618365\n",
            "Epoch 28 Loss 0.0000761738\n",
            "Epoch 29 Batch 0 Loss 0.0000618544\n",
            "Epoch 29 Loss 0.0000761643\n",
            "Epoch 30 Batch 0 Loss 0.0000618179\n",
            "Epoch 30 Loss 0.0000761367\n",
            "Epoch 31 Batch 0 Loss 0.0000617992\n",
            "Epoch 31 Loss 0.0000761012\n",
            "Epoch 32 Batch 0 Loss 0.0000617419\n",
            "Epoch 32 Loss 0.0000761023\n",
            "Epoch 33 Batch 0 Loss 0.0000617126\n",
            "Epoch 33 Loss 0.0000760674\n",
            "Epoch 34 Batch 0 Loss 0.0000616705\n",
            "Epoch 34 Loss 0.0000760430\n",
            "Epoch 35 Batch 0 Loss 0.0000616144\n",
            "Epoch 35 Loss 0.0000760187\n",
            "Epoch 36 Batch 0 Loss 0.0000615694\n",
            "Epoch 36 Loss 0.0000759781\n",
            "Epoch 37 Batch 0 Loss 0.0000615415\n",
            "Epoch 37 Loss 0.0000759484\n",
            "Epoch 38 Batch 0 Loss 0.0000614620\n",
            "Epoch 38 Loss 0.0000759391\n",
            "Epoch 39 Batch 0 Loss 0.0000614926\n",
            "Epoch 39 Loss 0.0000759403\n",
            "Epoch 40 Batch 0 Loss 0.0000615026\n",
            "Epoch 40 Loss 0.0000759158\n",
            "Epoch 41 Batch 0 Loss 0.0000614707\n",
            "Epoch 41 Loss 0.0000758795\n",
            "Epoch 42 Batch 0 Loss 0.0000614876\n",
            "Epoch 42 Loss 0.0000758494\n",
            "Epoch 43 Batch 0 Loss 0.0000614676\n",
            "Epoch 43 Loss 0.0000758317\n",
            "Epoch 44 Batch 0 Loss 0.0000614035\n",
            "Epoch 44 Loss 0.0000757946\n",
            "Epoch 45 Batch 0 Loss 0.0000613700\n",
            "Epoch 45 Loss 0.0000757778\n",
            "Epoch 46 Batch 0 Loss 0.0000614141\n",
            "Epoch 46 Loss 0.0000757636\n",
            "Epoch 47 Batch 0 Loss 0.0000614153\n",
            "Epoch 47 Loss 0.0000757658\n",
            "Epoch 48 Batch 0 Loss 0.0000614191\n",
            "Epoch 48 Loss 0.0000757485\n",
            "Epoch 49 Batch 0 Loss 0.0000614366\n",
            "Epoch 49 Loss 0.0000757305\n",
            "Epoch 50 Batch 0 Loss 0.0000614025\n",
            "Epoch 50 Loss 0.0000756284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-etJ3z0qcSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(val_x, val_y):\n",
        "  tensor_val_x = tf.convert_to_tensor(val_x)\n",
        "  tensor_val_y = tf.convert_to_tensor(val_y)\n",
        "\n",
        "  val_x_batch_size = tensor_val_x.shape[0]\n",
        "\n",
        "  hidden = [tf.zeros((val_x_batch_size, units))]\n",
        "  enc_out, enc_hidden = encoder(tensor_val_x, hidden)\n",
        "  \n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims(np.array([-1] * val_x_batch_size).astype(float).reshape(val_x_batch_size, 1), 1)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for t in range(tensor_val_y.shape[1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "    dec_input = tf.expand_dims(predictions, 1)\n",
        "\n",
        "    result.append(predictions.numpy())\n",
        "\n",
        "  output = tf.transpose(tf.convert_to_tensor(result), [1, 0, 2])\n",
        "  val_loss = loss_function(val_y, output).numpy()\n",
        "\n",
        "  return val_loss, output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqGzPm9JqcOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZV5YDgHXaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziO8AmM1qAeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MOzQ0xmkTCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DiAdnfza-_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(dataset, start_index, end_index):\n",
        "  data = []\n",
        "  target = []\n",
        "\n",
        "\n",
        "  for i in range(end_index - start_index):\n",
        "    data_item_id \n",
        "    data_series_x = dataset.iloc[1042, (start_index + i):(start_index + INPUT_SERIES_SIZE + i)].values\n",
        "    data_series_y = dataset.iloc[1042, (start_index + INPUT_SERIES_SIZE + i):(start_index + INPUT_SERIES_SIZE + OUTPUT_SERIES_SIZE + i)].values\n",
        "\n",
        "    if data_series_x.tolist().count(0) == len(data_series_x):\n",
        "      continue\n",
        "\n",
        "    data.append(np.reshape(data_series_x, (INPUT_SERIES_SIZE , 1)).astype(float))\n",
        "    target.append(np.reshape(data_series_y, (OUTPUT_SERIES_SIZE, 1)).astype(float))\n",
        "    \n",
        "  return np.array(data), np.array(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQXQni0svH-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = generate_data(df, 1, 1600)\n",
        "val_x, val_y = generate_data(df, 1700, 1800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bf9205d1-dd05-4433-8c99-20f87e09faa2",
        "id": "izpJnBC8-aDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x.shape # (999, 10, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1069, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HavcXp9oh6KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = len(train_x) // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSY8DYqngp48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWNf-_LdTBTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTnMFxwbvhyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, \n",
        "                                   return_sequences = True, \n",
        "                                   return_state = True, \n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVzy6Colvhvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlOA1MqqSlil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEGx2sejvho-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XLKBKIsvhj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, \n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True, \n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "    #self.fc = tf.keras.layers.Dense(self.dec_units)\n",
        "    self.fc = tf.keras.layers.Dense(1, activation = 'relu')\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    #x = tf.expand_dims(x, 1)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "    \n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaHQ_3KpfLqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi2YwdQ7kR1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O492UKsTf3cI",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_function = tf.keras.losses.MeanSquaredError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUaRd1oC_dy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUu-v3QyR-gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3EZwUiYgpv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    \n",
        "    dec_input = tf.expand_dims(tf.expand_dims([-1.0] * BATCH_SIZE, 1), 1)\n",
        "    #print(\"init: \", dec_input.shape)\n",
        "\n",
        "    for t in range(targ.shape[1]):\n",
        "    #  print(t)\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      #print(\"targ[:, t]: \", targ[:, t].shape, \"prev: \", dec_input.shape)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "     # print(\"after: \", dec_input.shape)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR1xySYPgptt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZF6bxEQgprO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss/STEPS_PER_EPOCH))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kxoPKltnAVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(val_x, val_y):\n",
        "  tensor_val_x = tf.convert_to_tensor(val_x)\n",
        "  tensor_val_y = tf.convert_to_tensor(val_y)\n",
        "\n",
        "  val_x_batch_size = tensor_val_x.shape[0]\n",
        "\n",
        "  hidden = [tf.zeros((val_x_batch_size, units))]\n",
        "  enc_out, enc_hidden = encoder(tensor_val_x, hidden)\n",
        "  \n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims(np.array([-1] * val_x_batch_size).astype(float).reshape(val_x_batch_size, 1), 1)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for t in range(tensor_val_y.shape[1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "    dec_input = tf.expand_dims(predictions, 1)\n",
        "\n",
        "    result.append(predictions.numpy())\n",
        "\n",
        "  output = tf.transpose(tf.convert_to_tensor(result), [1, 0, 2])\n",
        "  val_loss = loss_function(val_y, output).numpy()\n",
        "\n",
        "  return val_loss, output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-aagE4I0z-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, predict_result = evaluate(val_x, val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU3NdTqRNLuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ2F_d0iNLrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkVcly-sNLn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nADTQUsYNLkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wS-4-gG0z4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt \n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiFdNpaFBd9Y",
        "colab_type": "code",
        "outputId": "af412374-3d64-43c9-ddd4-903de99834fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "plt.plot(range(-60, 28), np.concatenate([val_x[2], val_y[2]], axis = 0))\n",
        "plt.plot(range(0, 28), predict_result[2].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd563d44668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAFlCAYAAABMeCkPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLlnyGwX4gGO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}